<?xml version="1.0" encoding="UTF-8"?>
<!-- 从高到地低 OFF 、 FATAL 、 ERROR 、 WARN 、 INFO 、 DEBUG 、 TRACE 、 ALL -->
<!-- 日志输出规则 根据当前ROOT 级别，日志输出时，级别高于root默认的级别时 会输出 -->
<!-- 以下 每个配置的 filter 是过滤掉输出文件里面，会出现高级别文件，依然出现低级别的日志信息，通过filter 过滤只记录本级别的日志 -->
<!-- 属性描述 scan：性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 
	debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 -->
<configuration scan="true" scanPeriod="60 seconds" debug="false">
	<!-- 定义日志文件 输入位置 -->
	<property name="log_dir" value="/data/webroot/chapter/logs" />
	<!-- 日志最大的历史 15天 -->
	<property name="maxHistory" value="30" />
	<property name="pattern"
		value="%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] [%-5level] %logger{30}.%method:%line [%X{reqKey}] - %msg%n" />


	<!-- ConsoleAppender 控制台输出日志 -->
	<appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
		<!-- 对日志进行格式化 -->
		<encoder>
			<pattern>${pattern}</pattern>
		</encoder>
	</appender>
	`
	<appender name="ERROR"
		class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 过滤器，只记录ERROR级别以上的日志 -->
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>ERROR</level>
		</filter>
		<file>${log_dir}/error.log</file>
		<!-- 每日或者单个文件超过300M是生成一个新的日志文件，当日志文件超过50个时删除更早的文件 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${log_dir}/error_%d{yyyy-MM-dd}_%i.log
			</fileNamePattern>
			<maxHistory>30</maxHistory>
			<timeBasedFileNamingAndTriggeringPolicy
				class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>300MB</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<encoder>
			<pattern>${pattern}</pattern>
			<immediateFlush>true</immediateFlush>
		</encoder>
	</appender>

	<appender name="INFO"
		class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 记录info级别以上的日志 -->
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>INFO</level>
		</filter>
		<file>${log_dir}/info.log</file>
		<!-- 每日或者单个文件超过300M是生成一个新的日志文件，当日志文件超过50个时删除更早的文件 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${log_dir}/info_%d{yyyy-MM-dd}_%i.log
			</fileNamePattern>
			<maxHistory>30</maxHistory>
			<timeBasedFileNamingAndTriggeringPolicy
				class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>300MB</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<encoder>
			<pattern>${pattern}</pattern>
			<immediateFlush>true</immediateFlush>
		</encoder>
	</appender>

	<appender name="EVENT"
		class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 记录info级别以上的日志 -->
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>INFO</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
		<file>${log_dir}/event.log</file>
		<!-- 每日或者单个文件超过300M是生成一个新的日志文件，当日志文件超过50个时删除更早的文件 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${log_dir}/event_%d{yyyy-MM-dd}_%i.log
			</fileNamePattern>
			<maxHistory>30</maxHistory>
			<timeBasedFileNamingAndTriggeringPolicy
				class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>300MB</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<encoder>
			<pattern>${pattern}</pattern>
			<immediateFlush>true</immediateFlush>
		</encoder>
	</appender>

	<appender name="EVENT-ERROR"
		class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 过滤器，只记录ERROR级别以上的日志 -->
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>WARN</level>
		</filter>
		<file>${log_dir}/event-error.log</file>
		<!-- 每日或者单个文件超过300M是生成一个新的日志文件，当日志文件超过50个时删除更早的文件 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${log_dir}/event-error_%d{yyyy-MM-dd}_%i.log
			</fileNamePattern>
			<maxHistory>30</maxHistory>
			<timeBasedFileNamingAndTriggeringPolicy
				class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
				<maxFileSize>300MB</maxFileSize>
			</timeBasedFileNamingAndTriggeringPolicy>
		</rollingPolicy>
		<encoder>
			<pattern>${pattern}</pattern>
			<immediateFlush>true</immediateFlush>
		</encoder>
	</appender>

	<logger name="com" level="INFO" additivity="false">
		<appender-ref ref="INFO" />
		<appender-ref ref="ERROR" />
		<appender-ref ref="STDOUT" />
	</logger>

	<logger name="org" level="INFO" additivity="false">
		<appender-ref ref="INFO" />
		<appender-ref ref="ERROR" />
	</logger>

	<logger name="com.github.pigeon.api" level="INFO" additivity="false">
		<appender-ref ref="EVENT" />
		<appender-ref ref="EVENT-ERROR" />
	</logger>


	<!-- root级别 DEBUG -->
	<root level="info">
		<!-- 控制台输出 -->
		<appender-ref ref="STDOUT" />
	</root>
</configuration>